{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to clean these imports up\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import special\n",
    "from scipy import integrate\n",
    "from scipy import interpolate\n",
    "from scipy import stats\n",
    "from scipy import optimize\n",
    "from numpy.random import default_rng\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Standardizing some of the font sizes for plots\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "plt.rcParams['font.weight'] = 'normal'\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "# Some of Matt's matplotlib style settings\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "plt.rcParams['figure.autolayout'] = False\n",
    "plt.rcParams['figure.figsize'] = 10, 6\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['axes.titlesize'] = 15\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['lines.linewidth'] = 2.0\n",
    "plt.rcParams['lines.markersize'] = 8\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "mpl.rc('axes',edgecolor='k')\n",
    "plt.rcParams['xtick.color'] = 'k'\n",
    "plt.rcParams['ytick.color'] = 'k'\n",
    "\n",
    "# Lighting the torch (pytorch...)\n",
    "from IPython import display\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"C:\\\\Users\\\\ericr\\\\Desktop\\\\Rutgers\\\\density_estimation\\\\Liouville\\\\naf\\\\torchkit\")\n",
    "sys.path.append(\"C:\\\\Users\\\\ericr\\\\Desktop\\\\Rutgers\\\\density_estimation\\\\Liouville\\\\naf\\\\torchkit\\\\torchkit\")\n",
    "sys.path.append(\"C:\\\\Users\\\\ericr\\\\Desktop\\\\Rutgers\\\\density_estimation\\\\Liouville\\\\naf\")\n",
    "\n",
    "import naf\n",
    "import scipy as sp\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import init\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler,MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h1> Density Estimation via NAF </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntropyDataset(Dataset):\n",
    "    \"\"\"Top tagging dataset.\"\"\"\n",
    "\n",
    "    def __init__(self,data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            datfile (string): File containing all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data=data\n",
    "        \n",
    "#        self.images, self.labels = read_images(datfile,Nread)\n",
    "\n",
    "    def __len__(self):\n",
    "        self.len=len(self.data)\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        datum = self.data[idx]\n",
    "\n",
    "        return datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.transpose(mwHalo.cartesianPhaseSpacePoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = EntropyDataset(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_batch_size=128\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=my_batch_size,\n",
    "                        shuffle=True,pin_memory=True)\n",
    "# BECAUSE THIS IS UNSUPERVISED DENSITY ESTIMATION WE USE THE SAME TEST=TRAIN SET\n",
    "test_loader = DataLoader(train_set, batch_size=1000,\n",
    "                        shuffle=False,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denaf = naf.DensityEstimator(flowtype=1,dim=6,lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denaf.fit(train_loader, save_directory='results/nfw_example/',total=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are any of these plots? 0_o\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5), dpi= 120)\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "\n",
    "_,_,_ = ax.hist(np.sqrt(np.sum(values[:,0:3]**2,axis=1)),bins=100)\n",
    "#ax.set_yscale('log')\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "\n",
    "_,_,_ = ax.hist(np.sqrt(np.sum(values[:,3:6]**2,axis=1)),bins=100)\n",
    "#ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's happening in the next few cells?\n",
    "\n",
    "logprob = np.zeros(len(values)) # initializing the log probability array\n",
    "gradient =np.zeros_like(values) # initializing the gradient array\n",
    "acceleration =np.zeros((values.shape[0],values.shape[-1],values.shape[-1])) # initializing the acceleration array\n",
    "\n",
    "min_epoch = 7\n",
    "\n",
    "for i in range(min_epoch,epochs):\n",
    "    denaf.mdl.load_state_dict(torch.load(\"results/nfw_example/nafmodel_\"+str(i)+\".dict\"))\n",
    "    logprob_temp= np.empty(0)\n",
    "    gradient_temp=np.empty(0)\n",
    "    acceleration_temp=np.empty(0)\n",
    "    for batch_idx, data in enumerate(test_loader):\n",
    "        logprob_temp=np.concatenate((logprob_temp,denaf.density(data.cuda().float()).cpu().detach().numpy()))\n",
    "        grad,acc = denaf.return_grad(data.cuda().float())\n",
    "        gradient_temp=np.concatenate((gradient_temp,grad.cpu().detach().numpy().flatten()))\n",
    "        acceleration_temp=np.concatenate((acceleration_temp,acc.cpu().detach().numpy().flatten()))\n",
    "    gradient_temp = gradient_temp.reshape(-1,values.shape[-1])\n",
    "    acceleration_temp = acceleration_temp.reshape(-1,values.shape[-1],values.shape[-1])\n",
    "            \n",
    "    logprob += logprob_temp\n",
    "    gradient += gradient_temp\n",
    "    acceleration += acceleration_temp       \n",
    "    \n",
    "logprob = logprob/len(range(90,100))\n",
    "gradient = gradient/len(range(90,100))\n",
    "acceleration = acceleration/len(range(90,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(logprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(acceleration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpoints = np.vstack([np.linspace(-30,30,20),\n",
    "                       np.linspace(-30,30,20),\n",
    "                       np.linspace(-30,30,20),\n",
    "                       np.linspace(-20,20,20),\n",
    "                       np.linspace(-20,20,20),\n",
    "                       np.linspace(-20,20,20)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
